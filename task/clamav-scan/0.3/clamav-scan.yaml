apiVersion: tekton.dev/v1
kind: Task
metadata:
  labels:
    app.kubernetes.io/version: "0.3"
    build.appstudio.redhat.com/build_type: "docker"
  annotations:
    tekton.dev/pipelines.minVersion: "0.12.1"
    tekton.dev/tags: "appstudio, hacbs"
  name: clamav-scan
spec:
  description: >-
    Scans the content of container images for viruses, malware, and other security threats using ClamAV.
    This version uses clamdscan with the clamd daemon for improved performance through database caching.
  params:
    - description: Image digest to scan.
      name: image-digest
      type: string
    - description: Image URL.
      name: image-url
      type: string
    - description: Number of threads to run in clamdscan parallel. Use 'auto' for optimal detection, or specify number (should be <= max-scan-threads).
      name: scan-threads
      type: string
      default: "auto"
    - description: Maximum number of scan threads allowed.
      name: max-scan-threads
      type: string
      default: "8"
    - description: Configmap name holding the certificate bundle file.
      name: ca-trust-config-map-name
      type: string
      default: trusted-ca
    - description: The name of the key containing the certificate bundle file.
      name: ca-trust-config-map-key
      type: string
      default: ca-bundle.crt
  results:
    - description: Images processed in the task.
      name: IMAGES_PROCESSED
    - description: Tekton task test output.
      name: TEST_OUTPUT
  steps:
    - env:
        - name: HOME
          value: /work
        - name: IMAGE_URL
          value: $(params.image-url)
        - name: IMAGE_DIGEST
          value: $(params.image-digest)
        - name: SCAN_THREADS
          value: $(params.scan-threads)
        - name: MAX_SCAN_THREADS
          value: $(params.max-scan-threads)
      image: quay.io/konflux-ci/clamav-db:latest
      # per https://kubernetes.io/docs/concepts/containers/images/#imagepullpolicy-defaulting
      # the cluster will set imagePullPolicy to IfNotPresent
      # also per direction from Ralph Bean, we want to use image digest based tags to use a cue to automation like dependabot or renovatebot to periodically submit pull requests that update the digest as new images are released.
      workingDir: /work
      # need to change user since 'oc image extract' requires more privileges when running as root permissions
      # https://bugzilla.redhat.com/show_bug.cgi?id=1969929
      securityContext:
        capabilities:
          add: ["SETFCAP"]
      computeResources:
        limits:
          memory: 16Gi
          cpu: 8
        requests:
          memory: 8Gi
          cpu: 4
      script: |
        #!/usr/bin/env bash

        # Auto-optimize thread count based on available resources
        AVAILABLE_CPUS=$(nproc)
        MAX_SCAN_THREADS=${MAX_SCAN_THREADS:-8}
        
        # Auto-detect optimal thread count if not specified
        if [ "${SCAN_THREADS:-auto}" = "auto" ]; then
          # Use 75% of available CPUs, but at least 1 and at most MAX_SCAN_THREADS
          threads=$((AVAILABLE_CPUS * 3 / 4))
          threads=$((threads < 1 ? 1 : threads))
          threads=$((threads > MAX_SCAN_THREADS ? MAX_SCAN_THREADS : threads))
          echo "Auto-detected optimal thread count: $threads (based on $AVAILABLE_CPUS available CPUs)"
        else
          threads=${SCAN_THREADS}
          if ! [[ "$threads" =~ ^[0-9]+$ ]] || [ "$threads" -lt 1 ]; then
            echo "ERROR: SCAN_THREADS must be a positive integer or 'auto', got: '$threads'"
            exit 1
          fi
        fi

        if ! [[ "$MAX_SCAN_THREADS" =~ ^[0-9]+$ ]] || [ "$MAX_SCAN_THREADS" -lt 1 ]; then
          echo "ERROR: MAX_SCAN_THREADS must be a positive integer, got: '$MAX_SCAN_THREADS'"
          exit 1
        fi

        # Cap threads to MAX_THREADS
        if [ "$threads" -gt "$MAX_SCAN_THREADS" ]; then
          echo "SCAN_THREADS ($threads) exceeds MAX_SCAN_THREADS ($MAX_SCAN_THREADS) â€” capping threads to: $MAX_SCAN_THREADS"
          threads="$MAX_SCAN_THREADS"
        fi

        echo "Using $threads scanning threads on $AVAILABLE_CPUS available CPU cores"

        set -euo pipefail
        . /utils.sh
        trap 'handle_error $(results.TEST_OUTPUT.path)' EXIT

        # Check if clamd is already running by looking for common socket locations
        CLAMD_SOCKET=""
        for socket in /var/run/clamd.scan/clamd.sock /var/run/clamd.sock /tmp/clamd.sock /var/lib/clamav/clamd.sock; do
          if [ -S "$socket" ]; then
            CLAMD_SOCKET="$socket"
            echo "Found existing clamd socket at: $CLAMD_SOCKET"
            break
          fi
        done

        # Test if clamd is responsive
        if [ -n "$CLAMD_SOCKET" ]; then
          if clamdscan --version >/dev/null 2>&1; then
            echo "clamd daemon is already running and responsive"
            USE_EXISTING_CLAMD=true
          else
            echo "Found socket but clamd not responsive, will start our own"
            USE_EXISTING_CLAMD=false
          fi
        else
          echo "No existing clamd socket found, will start our own"
          USE_EXISTING_CLAMD=false
        fi

        # Start our own clamd if needed
        if [ "$USE_EXISTING_CLAMD" = "false" ]; then
          echo "Starting clamd daemon for improved performance..."
          
          # Find the database directory
          DB_DIR=""
          for dir in /var/lib/clamav /usr/local/share/clamav /opt/clamav/share/clamav; do
            if [ -d "$dir" ] && [ -n "$(ls -A "$dir" 2>/dev/null)" ]; then
              DB_DIR="$dir"
              break
            fi
          done
          
          if [ -z "$DB_DIR" ]; then
            echo "ERROR: Could not find ClamAV database directory"
            exit 1
          fi
          
          echo "Using database directory: $DB_DIR"

          # Create optimized clamd configuration for maximum performance
          mkdir -p /tmp/clamd
          CLAMD_SOCKET="/tmp/clamd.sock"
          {
            echo "LocalSocket $CLAMD_SOCKET"
            echo "DatabaseDirectory $DB_DIR"
            echo "LogFile /tmp/clamd.log"
            echo "LogVerbose no"  # Reduce logging overhead
            echo "PidFile /tmp/clamd.pid"
            echo "User root"
            
            # Performance optimizations
            echo "MaxThreads $AVAILABLE_CPUS"  # Use all available CPU cores
            echo "MaxQueue 1000"  # Increase queue size for better throughput
            echo "IdleTimeout 300"  # Keep daemon alive longer
            echo "ReadTimeout 300"  # Increase read timeout
            echo "CommandReadTimeout 30"  # Optimize command timeout
            
            # Memory optimizations - use more of the available 16GB
            echo "MaxScanSize 8192M"  # Double the scan size limit
            echo "MaxFileSize 4096M"  # Double file size limit
            echo "MaxScanTime 0"
            echo "MaxFiles 0"
            echo "MaxRecursion 2000"  # Double recursion limits
            echo "MaxDirectoryRecursion 40000"  # Double directory recursion
            echo "MaxEmbeddedPE 8192M"  # Double embedded PE limit
            echo "MaxHTMLNormalize 20M"  # Double HTML limits
            echo "MaxHTMLNoTags 8192M"
            echo "MaxScriptNormalize 10M"  # Double script limits
            echo "MaxZipTypeRcg 8192M"  # Double ZIP limits
            echo "MaxPartitions 100000"  # Double partition limits
            echo "MaxIconsPE 200000"  # Double icon limits
            echo "MaxRecHWP3 40000"  # Double HWP3 limits
            
            # PCRE optimizations
            echo "PCREMatchLimit 200000000"  # Double PCRE limits
            echo "PCRERecMatchLimit 4000000"
            echo "PCREMaxFileSize 8192M"
            
            # Additional performance settings
            echo "ScanPE yes"
            echo "ScanELF yes"
            echo "ScanOLE2 yes"
            echo "ScanPDF yes"
            echo "ScanSWF yes"
            echo "ScanXMLDOCS yes"
            echo "ScanHWP3 yes"
            echo "ScanArchive yes"
            echo "AlertBrokenExecutables yes"
            echo "AlertBrokenMedia yes"
            echo "AlertEncrypted yes"
            echo "AlertEncryptedArchive yes"
            echo "AlertEncryptedDoc yes"
            echo "AlertMacros yes"
            echo "AlertPhishingSSLMismatch yes"
            echo "AlertPhishingCloak yes"
            echo "AlertPartitionIntersection yes"
            echo "HeuristicScanPrecedence yes"
            echo "StructuredDataDetection yes"
            echo "StructuredMinCreditCardCount 3"
            echo "StructuredMinSSNCount 3"
            echo "StructuredSSNFormatNormal yes"
            echo "StructuredSSNFormatStripped yes"
            
            # Disable unnecessary features for speed
            echo "ScanMail no"
            echo "MailFollowURLs no"
            echo "PhishingSignatures yes"
            echo "PhishingScanURLs yes"
            echo "HeuristicAlerts yes"
            
            # Optimize I/O and caching
            echo "ConcurrentDatabaseReload no"  # Avoid reload during scanning
            echo "CrossFilesystems yes"
            echo "FollowDirectorySymlinks no"
            echo "FollowFileSymlinks no"
          } > /tmp/clamd.conf

          clamd -c /tmp/clamd.conf &
          CLAMD_PID=$!
          
          # Wait for clamd to be ready
          echo "Waiting for clamd daemon to be ready..."
          timeout=60
          while ! test -S "$CLAMD_SOCKET"; do
            if [ $timeout -le 0 ]; then
              echo "ERROR: clamd daemon failed to start within 60 seconds"
              if [ -f /tmp/clamd.log ]; then
                echo "=== clamd.log ==="
                cat /tmp/clamd.log
              fi
              exit 1
            fi
            sleep 1
            timeout=$((timeout - 1))
          done
          
          # Give daemon a moment to fully initialize
          sleep 2
          
          # Test connection
          if ! clamdscan --config-file=/tmp/clamd.conf --version >/dev/null 2>&1; then
            echo "ERROR: Unable to connect to clamd daemon"
            if [ -f /tmp/clamd.log ]; then
              echo "=== clamd.log ==="
              cat /tmp/clamd.log
            fi
            exit 1
          fi
          
          echo "clamd daemon is ready"
          
          # Ensure clamd is stopped on exit
          trap 'kill $CLAMD_PID 2>/dev/null || true; handle_error $(results.TEST_OUTPUT.path)' EXIT
        fi

        imagewithouttag=$(echo $IMAGE_URL | sed "s/\(.*\):.*/\1/" | tr -d '\n')

        # strip new-line escape symbol from parameter and save it to variable
        imageanddigest=$(echo $imagewithouttag@$IMAGE_DIGEST)

        # check if image is attestation one, skip the clamav scan in such case
        if [[ $imageanddigest == *.att ]]
        then
            echo "$imageanddigest is an attestation image. Skipping ClamAV scan."
            exit 0
        fi

        images_processed_template='{"image": {"pullspec": "'"$IMAGE_URL"'", "digests": [%s]}}'
        digests_processed=()
        mkdir logs
        mkdir content
        cd content
        echo "Extracting image(s)."

        # Get the arch and image manifests by inspecting the image. This is mainly for identifying image indexes
        image_manifests=$(get_image_manifests -i "${imageanddigest}")
        if [ -n "$image_manifests" ]; then
          while read -r arch arch_sha; do
            destination=$(echo content-$arch)
            mkdir -p "$destination"
            arch_imageanddigest=$(echo $imagewithouttag@$arch_sha)

            echo "Running \"oc image extract\" on image of arch $arch"
            retry oc image extract --registry-config ~/.docker/config.json "$arch_imageanddigest" --path="/:${destination}" --filter-by-os="linux/${arch}"
            if [ $? -ne 0 ]; then
              echo "Unable to extract image for arch $arch. Skipping ClamAV scan!"
              exit 0
            fi

            # Get database version from clamdscan
            if [ "$USE_EXISTING_CLAMD" = "true" ]; then
              # Use existing clamd, try without config file first
              if clamdscan --version >/dev/null 2>&1; then
                db_version=$(clamdscan --version | sed 's|.*/\(.*\)/.*|\1|')
              else
                # Fallback to clamscan for version
                db_version=$(clamscan --version | sed 's|.*/\(.*\)/.*|\1|')
              fi
            else
              # Use our custom config
              db_version=$(clamdscan --config-file=/tmp/clamd.conf --version | sed 's|.*/\(.*\)/.*|\1|')
            fi

            if [[ "$threads" -eq 1 ]]; then
              # Optimized single-threaded mode
              echo "Single-threaded mode detected."
              echo "Starting high-performance scan for arch $arch using optimized clamdscan..."
              
              if [ "$USE_EXISTING_CLAMD" = "true" ]; then
                # Use existing clamd with performance optimizations
                nice -n -10 clamdscan \
                  --infected \
                  --fdpass \
                  --stream \
                  "${destination}" \
                  | tee "/work/logs/clamscan-result-1-$arch.log" || true
              else
                # Use our optimized clamd with performance flags
                nice -n -10 clamdscan \
                  --config-file=/tmp/clamd.conf \
                  --infected \
                  --fdpass \
                  --stream \
                  "${destination}" \
                  | tee "/work/logs/clamscan-result-1-$arch.log" || true
              fi
            else
              echo "Multi-threaded mode detected ($threads threads)."

              # Step 1: Generate complete manifest with optimized file discovery
              echo "Generating optimized file list..."
              # Use parallel find for faster file discovery on large images
              find "$destination" -type f -print0 | \
                parallel -0 -j $AVAILABLE_CPUS --pipe --block 100M \
                'while IFS= read -r -d "" file; do
                   size=$(stat -c "%s" "$file" 2>/dev/null || echo "0")
                   printf "%s\t%s\n" "$size" "$file"
                 done' > "$HOME/files_manifest.tsv" 2>/dev/null || {
                # Fallback to regular find if parallel is not available
                find "$destination" -type f -print0 | while IFS= read -r -d '' file; do
                  size=$(stat -c "%s" "$file")
                  printf "%s\t%s\n" "$size" "$file"
                done >"$HOME/files_manifest.tsv"
              }

              # Step 2: Sort by size with optimized approach
              echo "Sorting files by size (largest first for better load balancing)..."
              LC_ALL=C sort -nr -S 1G --parallel=$AVAILABLE_CPUS "$HOME/files_manifest.tsv" >"$HOME/files_manifest_sorted.tsv"

              # Step 3: Pre-allocate bucket files
              for i in $(seq 0 $((threads - 1))); do
                  : >"$HOME/file_bucket_$i.txt"
              done

              # Step 4: Intelligent file distribution for optimal load balancing
              echo "Distributing files across $threads buckets for optimal load balancing..."
              # Use largest-fit-decreasing algorithm for better balance
              python3 -c "
import sys
from collections import defaultdict

buckets = defaultdict(list)
bucket_sizes = defaultdict(int)
thread_count = $threads

with open('$HOME/files_manifest_sorted.tsv', 'r') as f:
    for line in f:
        if line.strip():
            size, path = line.strip().split('\t', 1)
            size = int(size)
            # Find bucket with smallest total size (load balancing)
            min_bucket = min(range(thread_count), key=lambda x: bucket_sizes[x])
            buckets[min_bucket].append(path)
            bucket_sizes[min_bucket] += size

# Write buckets to files
for i in range(thread_count):
    with open(f'$HOME/file_bucket_{i}.txt', 'w') as f:
        for path in buckets[i]:
            f.write(path + '\n')
            
print(f'Load balancing complete:')
for i in range(thread_count):
    print(f'  Bucket {i}: {len(buckets[i])} files, {bucket_sizes[i]/1024/1024:.1f} MB')
" 2>/dev/null || {
                # Fallback to simple round-robin if Python is not available
                i=0
                while IFS=$'\t' read -r size path; do
                    bucket=$((i % threads))
                    echo "$path" >>"$HOME/file_bucket_$bucket.txt"
                    ((i = i + 1))
                done <"$HOME/files_manifest_sorted.tsv"
              }

              # Step 5: Launch optimized clamdscan processes in parallel
              echo "Launching $threads optimized clamdscan processes..."
              for i in $(seq 0 $((threads - 1))); do
                  LOGFILE="/work/logs/clamscan-result-$i-$arch.log"
                  BUCKET_FILE="$HOME/file_bucket_$i.txt"

                  echo "Starting high-performance clamdscan on bucket $i..."

                  if [ "$USE_EXISTING_CLAMD" = "true" ]; then
                    # Use existing clamd with optimized flags
                    nice -n -10 clamdscan \
                        --infected \
                        --file-list="$BUCKET_FILE" \
                        --fdpass \
                        --stream \
                        | tee "$LOGFILE" || true &
                  else
                    # Use our optimized clamd with performance flags
                    nice -n -10 clamdscan \
                        --config-file=/tmp/clamd.conf \
                        --infected \
                        --file-list="$BUCKET_FILE" \
                        --fdpass \
                        --stream \
                        | tee "$LOGFILE" || true &
                  fi
              done

              echo "Waiting for all $threads clamdscan processes to complete..."
              # Monitor progress every 30 seconds
              while jobs %% >/dev/null 2>&1; do
                echo "$(date): Scanning in progress... $(jobs -r | wc -l) processes still running"
                sleep 30
              done
              wait
              echo "All scans completed successfully. Logs are in: /work/logs"
            fi

            digests_processed+=("\"$arch_sha\"")

            for logfile in /work/logs/clamscan-result-*-"$arch".log; do
              [ -e "$logfile" ] || continue

              echo "Executed-on: Scan was executed on clamdscan version - Database version: $db_version" | tee -a "$logfile"

              echo "Running EC on: $logfile"
              bucket_id=$(basename "$logfile" | sed -E 's/clamscan-result-([0-9]+)-.*\.log/\1/')
              json_input="/work/logs/clamsav-result-$bucket_id-$arch.json"
              json_output="/work/logs/clamscan-ec-test-$bucket_id-$arch.json"

              # Convert log to JSON format for EC
              jq -Rs '{ output: . }' "$logfile" > "$json_input"

              # Run EC (json)
              EC_EXPERIMENTAL=1 ec test \
                --namespace required_checks \
                --policy /project/clamav/virus-check.rego \
                -o json \
                "$json_input" || true

              # workaround: due to a bug in ec-cli, we cannot generate json and appstudio output at the same time, running it again
              EC_EXPERIMENTAL=1 ec test \
                --namespace required_checks \
                --policy /project/clamav/virus-check.rego \
                -o appstudio \
                "$json_input" | tee "$json_output" || true

              cat "$json_output"
            done
          done < <(echo "$image_manifests" | jq -r 'to_entries[] | "\(.key) \(.value)"')
        else
          echo "Failed to get image manifests from image \"$imageanddigest\""
          note="Task $(context.task.name) failed: Failed to get image manifests from image \"$imageanddigest\". For details, check Tekton task log."
          ERROR_OUTPUT=$(make_result_json -r "ERROR" -t "$note")
          echo "${ERROR_OUTPUT}" | tee "$(results.TEST_OUTPUT.path)"
          exit 0
        fi

        jq -s -rce '
          reduce .[] as $item ({"timestamp":"0","namespace":"","successes":0,"failures":0,"warnings":0,"result":"","note":""};
            {
            "timestamp" : (if .timestamp < $item.timestamp then $item.timestamp else .timestamp end),
            "namespace" : $item.namespace,
            "successes" : (.successes + $item.successes),
            "failures" : (.failures + $item.failures),
            "warnings" : (.warnings + $item.warnings),
            "result" : (if .result == "" or ($item.result == "SKIPPED" and .result == "SUCCESS") or ($item.result == "WARNING" and (.result == "SUCCESS" or .result == "SKIPPED")) or ($item.result == "FAILURE" and .result != "ERROR") or $item.result == "ERROR" then $item.result else .result end),
            "note" : (if .result == "" or ($item.result == "SKIPPED" and .result == "SUCCESS") or ($item.result == "WARNING" and (.result == "SUCCESS" or .result == "SKIPPED")) or ($item.result == "FAILURE" and .result != "ERROR") or $item.result == "ERROR" then $item.note else .note end)
            })' /work/logs/clamscan-ec-test-*.json | tee $(results.TEST_OUTPUT.path)

        # If the image is an Image Index, also add the Image Index digest to the list.
        if [[ "${digests_processed[*]}" != *"$IMAGE_DIGEST"* ]]; then
          digests_processed+=("\"$IMAGE_DIGEST\"")
        fi

        digests_processed_string=$(IFS=,; echo "${digests_processed[*]}")
        echo "${images_processed_template/\[%s]/[$digests_processed_string]}" | tee $(results.IMAGES_PROCESSED.path)
      volumeMounts:
        - mountPath: /work
          name: work
        - name: trusted-ca
          mountPath: /etc/pki/tls/certs/ca-custom-bundle.crt
          subPath: ca-bundle.crt
          readOnly: true
    - name: upload
      image: quay.io/konflux-ci/oras:latest@sha256:1beeecce012c99794568f74265c065839f9703d28306a8430b667f639343a98b
      computeResources:
        limits:
          memory: 512Mi
        requests:
          memory: 256Mi
          cpu: 100m
      env:
        - name: IMAGE_URL
          value: $(params.image-url)
        - name: IMAGE_DIGEST
          value: $(params.image-digest)
      workingDir: /work
      script: |
        #!/usr/bin/env bash

        cd logs

        for UPLOAD_FILE in clamscan-result*.log; do
          [ -e "$UPLOAD_FILE" ] || continue
          MEDIA_TYPE=text/vnd.clamav
          args+=("${UPLOAD_FILE}:${MEDIA_TYPE}")
        done
        for UPLOAD_FILE in clamscan-ec-test*.json; do
          [ -e "$UPLOAD_FILE" ] || continue
          MEDIA_TYPE=application/vnd.konflux.test_output+json
          args+=("${UPLOAD_FILE}:${MEDIA_TYPE}")
        done

        if [ -z "${args[*]}" ]; then
          echo "No files found. Skipping upload."
          exit 0;
        fi

        echo "Selecting auth"
        select-oci-auth $IMAGE_URL > $HOME/auth.json
        echo "Attaching to ${IMAGE_URL}"
        retry oras attach --no-tty --registry-config "$HOME/auth.json" --artifact-type application/vnd.clamav "${IMAGE_URL}" "${args[@]}"
      volumeMounts:
        - mountPath: /work
          name: work
  volumes:
    - name: work
      emptyDir: {}
    - name: trusted-ca
      configMap:
        name: $(params.ca-trust-config-map-name)
        items:
          - key: $(params.ca-trust-config-map-key)
            path: ca-bundle.crt
        optional: true 